{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating ssd loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "VAL_SIZE =0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 21\n",
    "NUM_CLASS_wo_BG = NUM_CLASS - 1 # as background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "anc_grid = 4\n",
    "k = 1\n",
    "\n",
    "anc_offset = 1/(anc_grid*2)\n",
    "anc_x = np.repeat(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\n",
    "anc_y = np.tile(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\n",
    "\n",
    "anc_ctrs = np.tile(np.stack([anc_x,anc_y], axis=1), (k,1))\n",
    "anc_sizes = np.array([[1/anc_grid,1/anc_grid] for i in range(anc_grid*anc_grid)])\n",
    "\n",
    "anchors = torch.tensor(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1250,  0.1250,  0.2500,  0.2500],\n",
       "        [ 0.1250,  0.3750,  0.2500,  0.2500],\n",
       "        [ 0.1250,  0.6250,  0.2500,  0.2500],\n",
       "        [ 0.1250,  0.8750,  0.2500,  0.2500],\n",
       "        [ 0.3750,  0.1250,  0.2500,  0.2500],\n",
       "        [ 0.3750,  0.3750,  0.2500,  0.2500],\n",
       "        [ 0.3750,  0.6250,  0.2500,  0.2500],\n",
       "        [ 0.3750,  0.8750,  0.2500,  0.2500],\n",
       "        [ 0.6250,  0.1250,  0.2500,  0.2500],\n",
       "        [ 0.6250,  0.3750,  0.2500,  0.2500],\n",
       "        [ 0.6250,  0.6250,  0.2500,  0.2500],\n",
       "        [ 0.6250,  0.8750,  0.2500,  0.2500],\n",
       "        [ 0.8750,  0.1250,  0.2500,  0.2500],\n",
       "        [ 0.8750,  0.3750,  0.2500,  0.2500],\n",
       "        [ 0.8750,  0.6250,  0.2500,  0.2500],\n",
       "        [ 0.8750,  0.8750,  0.2500,  0.2500]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sizes = torch.tensor(np.array([1/anc_grid]), requires_grad=False).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2500]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2, ctr+hw/2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.2500,  0.2500],\n",
       "        [ 0.0000,  0.2500,  0.2500,  0.5000],\n",
       "        [ 0.0000,  0.5000,  0.2500,  0.7500],\n",
       "        [ 0.0000,  0.7500,  0.2500,  1.0000],\n",
       "        [ 0.2500,  0.0000,  0.5000,  0.2500],\n",
       "        [ 0.2500,  0.2500,  0.5000,  0.5000],\n",
       "        [ 0.2500,  0.5000,  0.5000,  0.7500],\n",
       "        [ 0.2500,  0.7500,  0.5000,  1.0000],\n",
       "        [ 0.5000,  0.0000,  0.7500,  0.2500],\n",
       "        [ 0.5000,  0.2500,  0.7500,  0.5000],\n",
       "        [ 0.5000,  0.5000,  0.7500,  0.7500],\n",
       "        [ 0.5000,  0.7500,  0.7500,  1.0000],\n",
       "        [ 0.7500,  0.0000,  1.0000,  0.2500],\n",
       "        [ 0.7500,  0.2500,  1.0000,  0.5000],\n",
       "        [ 0.7500,  0.5000,  1.0000,  0.7500],\n",
       "        [ 0.7500,  0.7500,  1.0000,  1.0000]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])\n",
    "anchor_cnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start experiment on bbox loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4107,  0.0000,  0.6339,  0.3304],\n",
       "        [ 0.6696,  0.3616,  0.9241,  0.9196],\n",
       "        [ 0.6786,  0.4866,  0.9911,  0.6250],\n",
       "        [ 0.7098,  0.0848,  0.9911,  0.5491],\n",
       "        [ 0.5134,  0.8304,  0.6696,  0.9062]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep y_true_bboxes\n",
    "y_true_bbox = np.array([\n",
    "    (92, 0, 142, 74),\n",
    "    (150, 81, 207, 206),\n",
    "    (152, 109, 222, 140),\n",
    "    (159, 19, 222, 123), \n",
    "    (115, 186, 150, 203)\n",
    "])\n",
    "y_true_bbox = torch.from_numpy(y_true_bbox).float()\n",
    "y_true_bbox_tfm = y_true_bbox/IMG_SIZE\n",
    "\n",
    "y_true_bbox_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1080, -0.0347,  0.2906,  0.3261],\n",
       "        [ 0.1417,  0.2421,  0.2922,  0.4785],\n",
       "        [ 0.0196,  0.5356,  0.2044,  0.8610],\n",
       "        [ 0.0775,  0.6978,  0.3271,  0.8564],\n",
       "        [ 0.4078, -0.0155,  0.5699,  0.1291],\n",
       "        [ 0.2069,  0.2003,  0.4721,  0.4676],\n",
       "        [ 0.2096,  0.6762,  0.4768,  0.8098],\n",
       "        [ 0.0888,  0.8108,  0.4627,  1.1688],\n",
       "        [ 0.5177,  0.0201,  0.8106,  0.3266],\n",
       "        [ 0.4600,  0.1234,  0.6054,  0.4396],\n",
       "        [ 0.5480,  0.5559,  0.8999,  0.9239],\n",
       "        [ 0.5890,  0.7912,  0.8085,  0.9416],\n",
       "        [ 0.7408,  0.0005,  1.0161,  0.3461],\n",
       "        [ 0.6670,  0.1893,  0.9918,  0.3675],\n",
       "        [ 0.5752,  0.6059,  0.9471,  0.8310],\n",
       "        [ 0.6943,  0.6122,  0.9374,  0.9256]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep y_pred_bboxes\n",
    "y_pred_bboxes = torch.from_numpy(np.random.randn(anc_grid**2 * k, 4)).float()\n",
    "y_pred_bboxes = F.tanh(y_pred_bboxes) #squish between -1 to +1\n",
    "y_pred_bboxes_tfm_center = (y_pred_bboxes[:, :2] / 2 * grid_sizes) + anchors[:, :2]\n",
    "y_pred_bboxes_tfm_hw = (y_pred_bboxes[:, 2:] / 2 + 1) * anchors[:, 2:]\n",
    "y_pred_bboxes_tfm = hw2corners(y_pred_bboxes_tfm_center, y_pred_bboxes_tfm_hw)\n",
    "y_pred_bboxes_tfm #min y,x max y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect(box_a, box_b):\n",
    "    \"\"\"\n",
    "    box_a & box_b: min-y, min-x, max-y, max-x\n",
    "    \"\"\"\n",
    "    max_xy = torch.min(box_a[:, None, 2:], box_b[None, :, 2:])\n",
    "    min_xy = torch.max(box_a[:, None, :2], box_b[None, :, :2])\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[:, :, 0] * inter[:, :, 1]\n",
    "\n",
    "\n",
    "def box_sz(b): return ((b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1]))\n",
    "\n",
    "\n",
    "def jaccard(box_a, box_b):\n",
    "    \"\"\"\n",
    "    :param box_a: y_true_bbox x (min-y, min-x, max-y, max-x)\n",
    "    :param box_b: anchors x (min-y, min-x, max-y, max-x)\n",
    "    :return: iou\n",
    "    \"\"\"\n",
    "    inter = intersect(box_a, box_b)\n",
    "    union = box_sz(box_a).unsqueeze(1) + box_sz(box_b).unsqueeze(0) - inter\n",
    "    return inter / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = jaccard(y_true_bbox_tfm.data, anchor_cnr.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_ground_truth(overlaps):\n",
    "    \"\"\"\n",
    "    for each piror-box/predictions assign ground true with highest iou\n",
    "    then for each ground true assign its highest iou to piror-box;\n",
    "    \n",
    "    another way saying is\n",
    "    \n",
    "    for each ground true, assign to highest iou piror box\n",
    "    then for the rest unassigned piror box, assign ground true base highest iou\n",
    "    \"\"\"\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i, o in enumerate(prior_idx): \n",
    "        gt_idx[o] = i\n",
    "    return gt_overlap, gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_overlap, gt_idx = map_to_ground_truth(overlaps) #gt_overlap is iou with assigned ground true, gt_idx is idx of assigned ground true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  1,\n",
       "         1,  0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = gt_overlap > 0.4 #only count those piror-box : ground-true mapping with greater than 0.4; pos acts as a mask\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8,  11,  13,  14])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_idx = torch.nonzero(pos)[:, 0] #index of pos\n",
    "pos_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bbox = y_pred_bboxes_tfm[gt_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_loss = ((y_pred_bboxes_tfm[pos_idx] - gt_bbox[pos_idx]).abs()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4171)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start experiment on clf loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'BG',\n",
       " 1: 'aeroplane',\n",
       " 2: 'bicycle',\n",
       " 3: 'bird',\n",
       " 4: 'boat',\n",
       " 5: 'bottle',\n",
       " 6: 'bus',\n",
       " 7: 'car',\n",
       " 8: 'cat',\n",
       " 9: 'chair',\n",
       " 10: 'cow',\n",
       " 11: 'diningtable',\n",
       " 12: 'dog',\n",
       " 13: 'horse',\n",
       " 14: 'motorbike',\n",
       " 15: 'person',\n",
       " 16: 'pottedplant',\n",
       " 17: 'sheep',\n",
       " 18: 'sofa',\n",
       " 19: 'train',\n",
       " 20: 'tvmonitor'}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate = ['BG', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "id2cat = {i: j for i, j in enumerate(cate)}\n",
    "id2cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 18,   2,  16,  15,   8])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep y_true_cate\n",
    "\n",
    "y_true_cate = torch.from_numpy(np.random.randint(low = 1, high=20, size = 5))\n",
    "y_true_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3536,  1.3111, -0.0026,  0.5725, -0.7467,  0.5713, -0.0483,\n",
       "         -0.6868, -1.2230,  0.2332,  0.7010,  0.1773,  0.2344,  0.3787,\n",
       "         -0.8836,  0.0327,  0.8899, -0.3161, -0.9071,  0.4377,  0.1266],\n",
       "        [-2.4563,  2.9509,  0.6055,  0.4921, -0.5144, -1.7990, -0.6023,\n",
       "         -0.4690,  1.9904,  2.0677,  0.0736, -1.4805, -0.0607,  2.1589,\n",
       "         -0.4984,  2.6848,  0.2851,  0.7166,  0.0909, -2.1143,  1.1359],\n",
       "        [-0.5366,  0.6620,  1.3101, -0.1347, -0.7330,  1.1757, -0.0354,\n",
       "          0.2799,  0.5398,  0.5108,  0.5611,  1.6749, -0.8562,  0.5403,\n",
       "         -0.1553,  1.1331,  0.1431,  0.4295, -0.1932,  1.9006,  0.4027],\n",
       "        [ 0.8039, -0.0098,  0.9533, -0.0087,  1.1316,  0.6404,  0.6883,\n",
       "         -1.7918,  0.4554, -0.5598,  0.1084,  0.3894, -0.5494, -0.2221,\n",
       "         -1.0733,  0.5736, -0.0629,  0.4397, -0.4552, -2.2696, -0.6644],\n",
       "        [-0.1020,  0.5858,  1.6664, -0.1038,  0.8735,  1.3725, -1.4403,\n",
       "         -0.1914, -0.0473, -0.3023,  0.5078,  0.4402,  0.1672,  0.6958,\n",
       "         -1.0515, -0.1477,  0.2851,  2.6842, -0.8472, -1.0334,  0.7327],\n",
       "        [ 2.0112, -0.3717, -1.8612, -0.1195, -0.7526, -0.3162,  1.1511,\n",
       "         -0.6136, -0.6330,  0.6673, -1.6359,  0.4457, -1.5367, -0.0065,\n",
       "          1.1880, -2.0797, -0.3771,  1.4745,  0.4168, -0.7135,  0.3512],\n",
       "        [ 0.6816, -0.3757,  0.2830,  0.5767,  1.2070,  1.2808,  0.5049,\n",
       "          0.9245,  0.3349,  0.7158,  2.0449,  0.9643,  1.1447,  0.4454,\n",
       "          0.9927, -2.6705,  0.1862, -1.3027, -0.5808, -0.0926, -0.8719],\n",
       "        [ 0.6216,  0.0855,  0.1538, -0.2051,  2.3331,  1.8479,  0.8148,\n",
       "          1.3524, -0.6432,  0.5026,  0.2424,  0.4681, -1.0762, -0.7627,\n",
       "          0.4201, -2.1958, -0.2212,  2.2799,  0.1565,  1.1708, -0.0947],\n",
       "        [ 1.1537, -0.2641,  0.4941,  0.1000, -0.7133,  0.4095,  0.0588,\n",
       "          0.1619, -0.6692, -1.7596,  1.1262,  1.0100,  0.2867, -0.0606,\n",
       "          0.5094, -0.4401,  0.3524,  0.9044,  0.2723, -1.8193, -0.0467],\n",
       "        [ 0.2770, -1.4536, -0.0101, -0.2008, -0.4448,  0.0031, -0.8736,\n",
       "         -2.0192,  0.0880,  0.9505, -1.1743, -0.9610,  0.8002, -0.5497,\n",
       "          1.1348,  0.0841,  0.4882,  0.1358,  0.5746, -1.2660, -0.9548],\n",
       "        [ 0.0234, -1.0546, -0.4764, -0.0901, -0.6589,  0.9419,  2.1262,\n",
       "         -0.8556,  0.6286, -0.0182,  0.5808, -0.7937, -1.4260,  0.0248,\n",
       "          0.8415, -1.0496,  0.4608, -0.5372, -1.5028,  0.6915,  1.5479],\n",
       "        [-0.1263, -1.1564,  0.1881, -1.2471,  0.7995,  1.2907,  0.2867,\n",
       "          2.0758,  0.9500, -1.6791,  0.7859,  1.8940,  0.4433,  0.5025,\n",
       "         -0.4477,  0.5450, -0.9255,  0.2123, -1.7118,  0.4284,  3.0493],\n",
       "        [-0.0118,  0.7296, -1.0248,  0.8343,  0.4132,  1.3860,  1.2627,\n",
       "         -1.0633,  0.6050,  2.1037,  3.9479,  0.4490, -0.9221, -0.1381,\n",
       "          0.0645,  0.9191, -1.9187, -2.5278, -1.3244, -1.1460, -0.1864],\n",
       "        [ 2.0610, -1.2579, -0.5225, -1.1926,  0.4024, -0.4365, -0.7731,\n",
       "          1.6898, -0.4107,  0.6306, -1.4537,  0.1370, -1.1792,  0.4749,\n",
       "         -0.1893,  0.6559, -0.5415,  0.7097, -0.1883, -0.4198, -0.6880],\n",
       "        [ 0.0143,  0.3074, -0.2009, -0.7327,  0.6157, -0.5772, -0.6166,\n",
       "         -0.5722, -0.8531, -0.1356,  2.2823,  0.0179, -1.7214, -0.6530,\n",
       "          1.1136,  1.0556, -0.6712,  0.3934,  1.1756, -0.2715,  0.4435],\n",
       "        [-0.5788,  0.7007,  0.1507, -0.4491,  0.1431,  1.3241,  1.1829,\n",
       "          1.4133, -1.1706, -0.5381,  0.4251, -1.0656,  0.3627,  0.8619,\n",
       "          0.5120,  1.0732, -0.4840,  0.1348, -0.7417, -0.8633, -0.2807]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prep y_pred_cate\n",
    "\n",
    "y_pred_cate = torch.from_numpy(np.random.randn(anc_grid**2 * k, len(NUM_CLASS))).float()\n",
    "y_pred_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_clas = y_true_cate[gt_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  4,  3,  3,\n",
       "         2,  1])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_clas[1 - pos] = 0 #assign masked piror box to BG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   0,   0,   0,   0,   0,   0,   0,  18,   0,   0,   8,\n",
       "          0,  15,  16,   0])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = one_hot_embedding(gt_clas, num_classes = NUM_CLASS) #one-hot encoded y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 21])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t[:, 1:] #remove background from ground true as it doesnt count in error\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 20])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = y_pred_cate[:, 1:] #remove background from prediction as it doesnt count in error\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = None #weight for BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.5746)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_cate = F.binary_cross_entropy_with_logits(x, t, w, size_average=False) / NUM_CLASS_wo_BG\n",
    "loss_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
